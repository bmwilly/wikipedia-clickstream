{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n",
      "Loading tidyverse: tibble\n",
      "Loading tidyverse: tidyr\n",
      "Loading tidyverse: readr\n",
      "Loading tidyverse: purrr\n",
      "Loading tidyverse: dplyr\n",
      "Conflicts with tidy packages ---------------------------------------------------\n",
      "filter(): dplyr, stats\n",
      "invoke(): purrr, sparklyr\n",
      "lag():    dplyr, stats\n"
     ]
    }
   ],
   "source": [
    "library(ggraph)\n",
    "library(sparklyr)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in start_shell(master = master, spark_home = spark_home, spark_version = version, : sparklyr does not support Spark version: 2.3.0\n",
     "execution_count": 2,
     "output_type": "error",
     "traceback": [
      "Error in start_shell(master = master, spark_home = spark_home, spark_version = version, : sparklyr does not support Spark version: 2.3.0\nTraceback:\n",
      "1. spark_connect(master = \"local\")",
      "2. shell_connection(master = master, spark_home = spark_home, app_name = app_name, \n .     version = version, hadoop_version = hadoop_version, shell_args = shell_args, \n .     config = config, service = spark_config_value(config, \"sparklyr.gateway.service\", \n .         FALSE), remote = spark_config_value(config, \"sparklyr.gateway.remote\", \n .         spark_master_is_yarn_cluster(master)), extensions = extensions)",
      "3. start_shell(master = master, spark_home = spark_home, spark_version = version, \n .     app_name = app_name, config = config, jars = spark_config_value(config, \n .         \"sparklyr.jars.default\", list()), packages = spark_config_value(config, \n .         \"sparklyr.defaultPackages\"), extensions = extensions, \n .     environment = environment, shell_args = shell_args, service = service, \n .     remote = remote)",
      "4. stop(\"sparklyr does not support Spark version: \", versionSparkHome)"
     ]
    }
   ],
   "source": [
    "sc <- spark_connect(master = \"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_read_parquet(sc, \"dat\", \"/labs/data/processed/clean_data.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
